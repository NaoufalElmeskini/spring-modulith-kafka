# Guide de d√©pannage et exercices avanc√©s

## üîß D√©pannage courant

### Probl√®me : Kafka ne d√©marre pas

**Sympt√¥mes :**
- Erreur "Connection refused" dans les logs
- Les applications ne peuvent pas se connecter

**Solutions :**
```bash
# V√©rifier que Zookeeper est d√©marr√©
docker logs zookeeper

# V√©rifier les ports
netstat -tulpn | grep :2181  # Zookeeper
netstat -tulpn | grep :9092  # Kafka

# Red√©marrer l'infrastructure
docker-compose down && docker-compose up -d zookeeper kafka
```

### Probl√®me : Topic non cr√©√©

**Sympt√¥mes :**
- Erreur "Topic sensor-data does not exist"

**Solutions :**
```bash
# V√©rifier si le topic existe
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Cr√©er manuellement le topic
docker exec kafka kafka-topics --create \
  --topic sensor-data \
  --bootstrap-server localhost:9092 \
  --partitions 2 \
  --replication-factor 1
```

### Probl√®me : Consumer ne re√ßoit pas de messages

**Sympt√¥mes :**
- Producer envoie mais Consumer silent

**Solutions :**
```bash
# V√©rifier les consumer groups
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list

# V√©rifier les offsets
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 \
  --describe --group sensor-consumer-group

# R√©initialiser les offsets (pour tests)
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 \
  --reset-offsets --group sensor-consumer-group --topic sensor-data --to-earliest --execute
```

### Probl√®me : S√©rialisation/D√©s√©rialisation

**Sympt√¥mes :**
- JsonDeserializationException dans les logs

**Solutions :**
- V√©rifier que les classes `SensorData` sont identiques
- V√©rifier la configuration `TRUSTED_PACKAGES`
- Utiliser des logs d√©taill√©s pour diagnostiquer

---

## üéØ Exercices d'approfondissement

### Exercice 1 : Monitoring et m√©triques

**Objectif :** Ajouter des m√©triques de monitoring

**Instructions :**
1. Ajouter des compteurs pour messages envoy√©s/re√ßus
2. Mesurer les temps de traitement
3. Cr√©er des endpoints actuator pour exposer les m√©triques

**Code √† ajouter au Producer :**
```java
@Component
public class MetricsService {
    private final AtomicLong messagesSent = new AtomicLong();
    private final AtomicLong messagesFailures = new AtomicLong();
    
    public void incrementSent() { messagesSent.incrementAndGet(); }
    public void incrementFailure() { messagesFailures.incrementAndGet(); }
    
    @EventListener
    public void printStats(ContextRefreshedEvent event) {
        Executors.newScheduledThreadPool(1).scheduleAtFixedRate(() -> {
            logger.info("üìä Producer Stats - Envoy√©s: {}, √âchecs: {}", 
                       messagesSent.get(), messagesFailures.get());
        }, 10, 10, TimeUnit.SECONDS);
    }
}
```

### Exercice 2 : Gestion des erreurs avanc√©e

**Objectif :** Impl√©menter la gestion d'erreurs robuste

**Instructions :**
1. Ajouter un topic `sensor-data-errors` pour les messages en erreur
2. Impl√©menter un Dead Letter Queue pattern
3. G√©rer les retry automatiques avec backoff

**Configuration Consumer avec retry :**
```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, SensorData> 
    kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, SensorData> factory = 
        new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    
    // Configuration retry
    factory.setCommonErrorHandler(new DefaultErrorHandler(
        new FixedBackOff(1000L, 3) // 3 retry avec 1s d'intervalle
    ));
    
    return factory;
}
```

### Exercice 3 : Partitioning avanc√©

**Objectif :** Comprendre l'impact du partitioning

**Instructions :**
1. Modifier le Producer pour utiliser un partitioner custom
2. Cr√©er un topic avec 4 partitions
3. Observer la distribution des messages

**Partitioner custom :**
```java
@Component
public class SensorPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, 
                        Object value, byte[] valueBytes, Cluster cluster) {
        // Partitioning bas√© sur le hash du sensorId
        String sensorId = (String) key;
        return Math.abs(sensorId.hashCode()) % cluster.partitionCountForTopic(topic);
    }
}
```

### Exercice 4 : Consumer Groups multiples

**Objectif :** D√©montrer la scalabilit√© avec plusieurs consumers

**Instructions :**
1. Cr√©er 2 consumer groups diff√©rents
2. Un pour l'alerting, un pour l'archivage
3. Observer que chaque groupe re√ßoit tous les messages

**Consumer d'alerting :**
```java
@KafkaListener(topics = "sensor-data", groupId = "alert-consumer-group")
public void processAlerts(ConsumerRecord<String, SensorData> record) {
    SensorData data = record.value();
    if (data.getValue() < 200 || data.getValue() > 240) {
        logger.warn("üö® ALERTE - Capteur {} : tension critique {:.2f}V", 
                   data.getSensorId(), data.getValue());
    }
}
```

### Exercice 5 : Streaming temps r√©el avec Kafka Streams

**Objectif :** Introduire le traitement en streaming

**Instructions :**
1. Ajouter Kafka Streams au projet
2. Calculer la moyenne mobile sur 5 messages
3. Cr√©er un topic de sortie pour les statistiques

**D√©pendance √† ajouter :**
```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-streams</artifactId>
</dependency>
```

**Configuration Kafka Streams :**
```java
@Configuration
@EnableKafkaStreams
public class KafkaStreamsConfig {
    
    @Bean
    public KafkaStreams kafkaStreams() {
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "sensor-stats-app");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        
        StreamsBuilder builder = new StreamsBuilder();
        
        KStream<String, SensorData> sensorStream = builder.stream("sensor-data");
        
        // Calcul de moyenne mobile par capteur
        sensorStream
            .groupByKey()
            .windowedBy(TimeWindows.of(Duration.ofMinutes(1)))
            .aggregate(
                () -> new SensorStats(),
                (key, value, aggregate) -> aggregate.add(value),
                Materialized.as("sensor-stats-store")
            )
            .toStream()
            .to("sensor-stats");
            
        return new KafkaStreams(builder.build(), props);
    }
}
```

---

## üìö Questions d'entretien techniques

### Questions de base

1. **Quelle est la diff√©rence entre une queue et un topic ?**
   - Queue : 1 message ‚Üí 1 consumer (load balancing)
   - Topic : 1 message ‚Üí N consumers (publish-subscribe)

2. **Pourquoi utiliser Kafka plut√¥t que RabbitMQ ?**
   - Kafka : haute performance, persistance, replay des messages
   - RabbitMQ : routing complexe, transactions ACID

3. **Qu'est-ce qu'un offset et pourquoi est-il important ?**
   - Position unique d'un message dans une partition
   - Permet le replay, la reprise apr√®s crash, l'idempotence

### Questions avanc√©es

4. **Comment g√©rer le back-pressure dans Kafka ?**
   - Configuration des buffers producer
   - Limitation du throughput consumer
   - Monitoring de la lag

5. **Que se passe-t-il si une partition leader tombe ?**
   - √âlection automatique d'un nouveau leader
   - Les r√©pliques prennent le relais
   - Importance du replication factor

6. **Comment assurer l'exactly-once processing ?**
   - Idempotent producer
   - Transactional semantics
   - Exactly-once streams processing

### Questions de production

7. **Comment monitorer un cluster Kafka ?**
   - JMX metrics (lag, throughput, errors)
   - Kafka Manager / Confluent Control Center
   - Alerting sur consumer lag

8. **Strat√©gies de sizing des partitions ?**
   - Bas√© sur le throughput cible
   - Nombre de consumers parall√®les
   - Taille des messages et retention

---

## üöÄ Prochaines √©tapes

### Pour aller plus loin

1. **Schema Registry** : √âvolution des sch√©mas de donn√©es
2. **Kafka Connect** : Int√©gration avec bases de donn√©es
3. **KSQL** : Requ√™tes SQL sur les streams
4. **S√©curit√©** : SSL, SASL, ACLs
5. **Multi-cluster** : Replication entre datacenters

### Projets pratiques sugg√©r√©s

1. **IoT Dashboard** : Visualisation temps r√©el des capteurs
2. **Event Sourcing** : Syst√®me de commandes e-commerce
3. **CDC (Change Data Capture)** : Synchronisation BDD ‚Üí Kafka
4. **Microservices** : Communication asynchrone entre services

Ce TP vous donne les bases solides pour ma√Ætriser Kafka et √™tre confiant lors d'entretiens techniques. La progression du simple au complexe permet d'assimiler progressivement les concepts cl√©s du streaming de donn√©es.

**Temps estim√© :** 1-2 jours selon votre niveau d'approfondissement des exercices avanc√©s.